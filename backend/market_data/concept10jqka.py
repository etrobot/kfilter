# -*- coding: utf-8 -*-
import asyncio
import requests
import pandas as pd
import time
import json
import traceback
import random
from playwright.async_api import async_playwright


# è¯·æ±‚é¢‘ç‡æ§åˆ¶
_last_request_time = 0
_request_lock = asyncio.Lock() if hasattr(asyncio, 'Lock') else None
MIN_REQUEST_INTERVAL = 3.0  # æœ€å°è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
MAX_REQUEST_INTERVAL = 8.0  # æœ€å¤§è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
PAGE_REQUEST_DELAY = 5.0  # é¡µé¢è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
MAX_CONCURRENT_REQUESTS = 3  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
_request_semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS) if hasattr(asyncio, 'Semaphore') else None
_forbidden_count = 0  # 403/429é”™è¯¯è®¡æ•°å™¨
_RATE_LIMIT_THRESHOLD = 3  # è§¦å‘æ›´ä¸¥æ ¼é™åˆ¶çš„é˜ˆå€¼
_FORBIDDEN_RESET_THRESHOLD = 10  # æˆåŠŸè¯·æ±‚æ•°è¾¾åˆ°æ­¤å€¼æ—¶é‡ç½®forbidden_count
_success_count = 0  # è¿ç»­æˆåŠŸè¯·æ±‚è®¡æ•°å™¨


def safe_request(url, headers=None, timeout=30, max_retries=5, base_delay=3):
    """
    å¸¦æœ‰é‡è¯•å’Œå»¶è¿Ÿæœºåˆ¶çš„HTTPè¯·æ±‚å‡½æ•°

    Args:
        url: è¯·æ±‚URL
        headers: è¯·æ±‚å¤´
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå®é™…å»¶è¿Ÿä¼šåœ¨æ­¤åŸºç¡€ä¸Šéšæœºæ³¢åŠ¨

    Returns:
        Responseå¯¹è±¡ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    global _last_request_time, _forbidden_count

    for attempt in range(max_retries):
        try:
            # é¢‘ç‡æ§åˆ¶ï¼šç¡®ä¿è¯·æ±‚é—´éš”
            current_time = time.time()
            time_since_last = current_time - _last_request_time
            if time_since_last < MIN_REQUEST_INTERVAL:
                sleep_time = MIN_REQUEST_INTERVAL - time_since_last + random.uniform(0, 2)
                print(f"é¢‘ç‡æ§åˆ¶ï¼šç­‰å¾… {sleep_time:.1f} ç§’")
                time.sleep(sleep_time)

            # å‘é€è¯·æ±‚
            response = requests.get(url, headers=headers, timeout=timeout)
            _last_request_time = time.time()

            # æ£€æŸ¥æ˜¯å¦è¢«é™æµ
            if response.status_code == 429:
                retry_after = int(response.headers.get('Retry-After', base_delay * (2 ** attempt)))
                retry_after = max(retry_after, 30)  # æœ€å°ç­‰å¾…30ç§’
                print(f"è¯·æ±‚è¿‡äºé¢‘ç¹(429)ï¼Œç­‰å¾… {retry_after} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
                time.sleep(retry_after)
                _forbidden_count += 1
                continue

            # æ£€æŸ¥æ˜¯å¦è¢«å°ç¦
            if response.status_code == 403:
                delay = base_delay * (2 ** attempt) + random.uniform(5, 10)
                delay = max(delay, 60)  # æœ€å°ç­‰å¾…60ç§’
                print(f"è¯·æ±‚è¢«æ‹’ç»(403)ï¼Œå¯èƒ½è§¦å‘åçˆ¬ï¼Œç­‰å¾… {delay:.1f} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
                time.sleep(delay)
                _forbidden_count += 1
                continue

            # æ£€æŸ¥å“åº”
            response.raise_for_status()
            reset_forbidden_count_on_success()
            return response

        except requests.exceptions.Timeout:
            delay = base_delay * (2 ** attempt) + random.uniform(5, 15)
            print(f"è¯·æ±‚è¶…æ—¶ï¼Œç­‰å¾… {delay:.1f} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
            time.sleep(delay)

        except requests.exceptions.ConnectionError:
            delay = base_delay * (2 ** attempt) + random.uniform(10, 20)
            print(f"è¿æ¥é”™è¯¯ï¼Œç­‰å¾… {delay:.1f} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
            time.sleep(delay)

        except requests.exceptions.RequestException as e:
            delay = base_delay * (2 ** attempt) + random.uniform(5, 10)
            print(f"è¯·æ±‚å¼‚å¸¸: {e}ï¼Œç­‰å¾… {delay:.1f} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})...")
            time.sleep(delay)

    print(f"è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries}): {url}")
    return None


def get_rate_limit_delay():
    """
    æ ¹æ®å½“å‰é”™è¯¯è®¡æ•°è·å–é€‚å½“çš„å»¶è¿Ÿæ—¶é—´
    """
    global _forbidden_count
    if _forbidden_count >= _RATE_LIMIT_THRESHOLD:
        # å¦‚æœå¤šæ¬¡è§¦å‘é™åˆ¶ï¼Œä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿ
        base_delay = 10.0 + (_forbidden_count - _RATE_LIMIT_THRESHOLD) * 5.0
        # ä½¿ç”¨æŒ‡æ•°é€€é¿ï¼Œæœ€å°30ç§’ï¼Œæœ€å¤§300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰
        delay = min(max(base_delay, 30.0), 300.0)
        print(f"âš ï¸ é¢‘ç¹é™åˆ¶è­¦å‘Š: å·²è§¦å‘ {_forbidden_count} æ¬¡é™åˆ¶ï¼Œå»¶è¿Ÿ {delay:.1f} ç§’")
        return delay
    return PAGE_REQUEST_DELAY


def reset_forbidden_count_on_success():
    """
    æˆåŠŸè¯·æ±‚åï¼Œé€æ­¥é‡ç½®forbiddenè®¡æ•°å™¨
    """
    global _forbidden_count, _success_count
    _success_count += 1
    
    if _success_count >= _FORBIDDEN_RESET_THRESHOLD and _forbidden_count > 0:
        _forbidden_count = max(0, _forbidden_count - 1)
        _success_count = 0
        print(f"âœ“ è¿ç»­æˆåŠŸ {_FORBIDDEN_RESET_THRESHOLD} æ¬¡ï¼Œé™ä½é™åˆ¶ç­‰çº§ (å½“å‰: {_forbidden_count})")


def report_rate_limit_status():
    """
    æŠ¥å‘Šå½“å‰çš„é€Ÿç‡é™åˆ¶çŠ¶æ€
    """
    global _forbidden_count, _success_count
    if _forbidden_count > 0:
        print(f"ğŸ“Š é€Ÿç‡é™åˆ¶çŠ¶æ€: é™åˆ¶æ¬¡æ•°={_forbidden_count}, æˆåŠŸæ¬¡æ•°={_success_count}/{_FORBIDDEN_RESET_THRESHOLD}")
    return {"forbidden_count": _forbidden_count, "success_count": _success_count}


async def safe_page_navigation(page, url, timeout=30000, max_retries=3):
    """
    å®‰å…¨çš„é¡µé¢å¯¼èˆªå‡½æ•°ï¼Œå¸¦æœ‰é‡è¯•å’Œå»¶è¿Ÿæœºåˆ¶

    Args:
        page: Playwrighté¡µé¢å¯¹è±¡
        url: ç›®æ ‡URL
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    global _forbidden_count
    
    for attempt in range(max_retries):
        try:
            # æ·»åŠ é€‚åº”æ€§é¡µé¢å¯¼èˆªå»¶è¿Ÿ
            rate_limit_delay = get_rate_limit_delay()
            await asyncio.sleep(rate_limit_delay + random.uniform(1, 3))

            await page.goto(url, wait_until="networkidle", timeout=timeout)

            # æ£€æŸ¥æ˜¯å¦è¢«å°ç¦
            page_content = await page.content()
            if "forbidden." in page_content.lower():
                delay = 60 * (2 ** attempt)
                print(f"æ£€æµ‹åˆ°è®¿é—®é™åˆ¶ï¼ˆç¬¬ {_forbidden_count + 1} æ¬¡ï¼‰ï¼Œç­‰å¾… {delay} ç§’...")
                await asyncio.sleep(delay)
                _forbidden_count += 1
                continue

            reset_forbidden_count_on_success()
            return True

        except Exception as e:
            delay = 5 * (2 ** attempt) + random.uniform(3, 8)
            print(f"é¡µé¢å¯¼èˆªå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}ï¼Œç­‰å¾… {delay:.1f} ç§’...")
            await asyncio.sleep(delay)

    print(f"é¡µé¢å¯¼èˆªå¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries}): {url}")
    return False


def parse_market_cap(text):
    """è§£ææµé€šå¸‚å€¼ï¼Œè½¬æ¢ä¸ºäº¿å…ƒ"""
    if not text or text == "--" or text == "-":
        return None
    try:
        original_text = text
        # åˆ¤æ–­å•ä½
        is_wan = "ä¸‡" in original_text

        # ç§»é™¤å•ä½
        text = text.replace("äº¿", "").replace("ä¸‡", "").strip()
        value = float(text)

        # å¦‚æœæ˜¯ä¸‡å…ƒï¼Œè½¬æ¢ä¸ºäº¿
        if is_wan:
            value = value / 10000

        return value
    except Exception:
        return None


def parse_pe_ratio(text):
    """è§£æå¸‚ç›ˆç‡"""
    if not text or text == "--" or text == "-":
        return None
    try:
        return float(text)
    except Exception:
        return None


async def crawl(p_url):
    """
    çˆ¬å–æ¿å—åç§°ä»¥åŠä»£ç 
    """
    # è·å–æ’é™¤çš„æ¦‚å¿µåˆ—è¡¨
    headers2 = {
        "X-Bmob-Application-Id": "ca8cc0da5351b1bef80ec5371ee3532e",
        "X-Bmob-REST-API-Key": "b70d44aedda27b342257ba6ac9edc39d",
        "Content-Type": "application/json",
        "Connection": "close",
    }

    try:
        response = safe_request(
            "https://api2.bmob.cn/1/classes/text/mI76888D", 
            headers=headers2,
            max_retries=3,
            base_delay=2
        )
        if response:
            excludecpt = (
                json.loads(response.text)["text"]
                .replace("ï¼Œ", ",")
                .split(",")
            )
        else:
            print("è·å–æ’é™¤åˆ—è¡¨å¤±è´¥: è¯·æ±‚è¿”å›None")
            excludecpt = []
    except Exception as e:
        print(f"è·å–æ’é™¤åˆ—è¡¨å¤±è´¥: {e}")
        excludecpt = []

    async with async_playwright() as p:
        # ä½¿ç”¨ chromium headless shellï¼ˆæœ€è½»é‡ï¼‰+ ååçˆ¬ç­–ç•¥
        browser = await p.chromium.launch(
            headless=True, 
            channel="chromium-headless-shell",
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
            ]
        )
        
        # åˆ›å»ºä¸Šä¸‹æ–‡ï¼Œè®¾ç½®çœŸå®çš„æµè§ˆå™¨ç‰¹å¾
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080},
            locale='zh-CN',
        )
        
        page = await context.new_page()
        
        # éšè— webdriver ç‰¹å¾
        await page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        """)

        # è·å–ä¸»é¡µé¢
        if not await safe_page_navigation(page, p_url, timeout=30000):
            print(f"è·å–ä¸»é¡µé¢å¤±è´¥ï¼Œå…³é—­æµè§ˆå™¨")
            await browser.close()
            return
        await page.wait_for_timeout(3000)  # å¢åŠ ç­‰å¾…æ—¶é—´ç¡®ä¿JSåŠ è½½

        # æå–æ¿å—åç§°å’Œä»£ç 
        try:
            # æå–éšè—å­—æ®µ gnSection ä¸­çš„æ¿å—ä»£ç 
            gn_section_input = await page.query_selector("input#gnSection")
            if not gn_section_input:
                print("æœªæ‰¾åˆ° gnSection éšè—å­—æ®µ")
                await browser.close()
                return
            
            gn_section_value = await gn_section_input.get_attribute("value")
            if not gn_section_value:
                print("gnSection å­—æ®µå€¼ä¸ºç©º")
                await browser.close()
                return
            
            # è§£æ JSON æ•°æ®
            gn_data = json.loads(gn_section_value)
            
            # æå–æ¿å—åç§°å’Œä»£ç 
            thsgnbk = []
            bkcode = []  # platecode - ä¿å­˜åˆ°æ•°æ®åº“
            cid_list = []  # cid - ç”¨äºæ„å»ºURL
            
            for key, value in gn_data.items():
                if isinstance(value, dict) and "platecode" in value and "platename" in value and "cid" in value:
                    platecode = value["platecode"]
                    platename = value["platename"]
                    cid = value["cid"]
                    thsgnbk.append(platename)
                    bkcode.append(platecode)
                    cid_list.append(cid)

            if len(thsgnbk) != len(bkcode):
                print(
                    f"è­¦å‘Š: æ¿å—åç§°æ•°é‡({len(thsgnbk)})ä¸ä»£ç æ•°é‡({len(bkcode)})ä¸åŒ¹é…"
                )

            data = {"Name": thsgnbk, "CID": cid_list}
            gnbk = pd.DataFrame(data, index=bkcode)

            bk_id = []
            bk_name = []
            print(f"æ‰¾åˆ° {len(gnbk)} ä¸ªæ¿å—")
            print(gnbk.index)
            start = time.time()

            for index, row in gnbk.iterrows():
                if index in excludecpt:
                    print(f"è·³è¿‡æ’é™¤çš„æ¿å—: {row['Name']}")
                    continue

                s_id = []
                s_name = []
                bk_code = index  # platecode - ä¿å­˜åˆ°æ•°æ®åº“
                cid = row["CID"]  # cid - ç”¨äºæ„å»ºURL
                name = row["Name"]
                url = p_url + "/detail/code/" + cid + "/"
                print(f"\nå¤„ç†æ¿å—: {name} (platecode={bk_code}, cid={cid})")
                report_rate_limit_status()

                # è·å–æ¿å—è¯¦æƒ…é¡µ
                if not await safe_page_navigation(page, url, timeout=30000):
                    print(f"è·å–æ¿å—è¯¦æƒ…é¡µå¤±è´¥ {name}")
                    continue
                await page.wait_for_timeout(2000)

                # å¾—å‡ºæ¿å—æˆåˆ†è‚¡æœ‰å¤šå°‘é¡µ
                try:
                    page_locator = page.locator("span#m-page")
                    page_text = await page_locator.text_content()
                    if page_text:
                        page = int(page_text.strip().split("/")[-1])
                        print(f"è¯¥æ¿å—å…±æœ‰ {page} é¡µ")
                    else:
                        page = 1
                except Exception:
                    page = 1

                # éå†æ‰€æœ‰é¡µé¢
                count = 1
                while count <= page:
                    try:
                        curl = (
                            p_url
                            + "/detail/field/199112/order/desc/page/"
                            + str(count)
                            + "/ajax/1/code/"
                            + bk_code
                        )
                        print(f"è·å–ç¬¬ {count}/{page} é¡µ: {curl}")

                        if not await safe_page_navigation(page, curl, timeout=30000):
                            continue
                        await page.wait_for_timeout(1000)

                        # æˆåˆ†è‚¡ä»£ç  - ä»è¡¨æ ¼ä¸­æå–
                        stock_rows = await page.query_selector_all("table tbody tr")
                        stock_code = []

                        for row in stock_rows:
                            # ç¬¬2åˆ—æ˜¯ä»£ç 
                            code_elem = await row.query_selector("td:nth-child(2) a")
                            if code_elem:
                                text = await code_elem.text_content()
                                if text:
                                    stock_code.append(text.strip())

                        stock_name = []  # æš‚æ—¶ä¸ç”¨ï¼Œä¿æŒå…¼å®¹æ€§

                        if len(stock_code) > 0:
                            print(f"æ‰¾åˆ° {len(stock_code)} åªæˆåˆ†è‚¡")
                            s_id += stock_code
                            s_name += stock_name
                            bk_id.extend([bk_code] * len(stock_code))
                            bk_name.extend([name] * len(stock_name))
                        else:
                            print("è¯¥é¡µæ²¡æœ‰æ‰¾åˆ°æˆåˆ†è‚¡")

                        count += 1
                        await asyncio.sleep(2)

                    except Exception as e:
                        print(f"è·å–ç¬¬ {count} é¡µå¤±è´¥: {e}")
                        count += 1
                        await asyncio.sleep(2)
                        continue

                print(f"æ¿å— {name} å®Œæˆï¼Œå…± {len(s_id)} åªæˆåˆ†è‚¡")

            end = time.time()
            await browser.close()
            print(
                f"\n{p_url} çˆ¬å–ç»“æŸï¼ï¼\nå¼€å§‹æ—¶é—´ï¼š{time.ctime(start)}\nç»“æŸæ—¶é—´ï¼š{time.ctime(end)}\nè€—æ—¶ï¼š{end - start:.2f}ç§’"
            )

        except Exception as e:
            print(f"çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            await browser.close()


async def collect_concept_data(
    p_url: str,
    on_concept_collected=None,
) -> tuple[list[dict], list[dict]]:
    """
    é‡‡é›†æ¦‚å¿µæ¿å—å’Œæˆåˆ†è‚¡æ•°æ®ï¼Œè¿”å›ç»“æ„åŒ–æ•°æ®
    è¿”å›: (concepts_list, stocks_list)
    """
    concepts_list = []
    stocks_list = []

    async with async_playwright() as p:
        # ä½¿ç”¨ chromium headless shellï¼ˆæœ€è½»é‡ï¼‰+ ååçˆ¬ç­–ç•¥
        browser = await p.chromium.launch(
            headless=True, 
            channel="chromium-headless-shell",
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
            ]
        )
        
        # åˆ›å»ºä¸Šä¸‹æ–‡ï¼Œè®¾ç½®çœŸå®çš„æµè§ˆå™¨ç‰¹å¾
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080},
            locale='zh-CN',
        )
        
        page = await context.new_page()
        
        # éšè— webdriver ç‰¹å¾
        await page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        """)

        if not await safe_page_navigation(page, p_url, timeout=30000):
            print(f"è·å–ä¸»é¡µé¢å¤±è´¥")
            await browser.close()
            return concepts_list, stocks_list
        await page.wait_for_timeout(3000)  # å¢åŠ ç­‰å¾…æ—¶é—´ç¡®ä¿JSåŠ è½½

        try:
            # æå–éšè—å­—æ®µ gnSection ä¸­çš„æ¿å—ä»£ç 
            gn_section_input = await page.query_selector("input#gnSection")
            if not gn_section_input:
                print("æœªæ‰¾åˆ° gnSection éšè—å­—æ®µ")
                await browser.close()
                return concepts_list, stocks_list
            
            gn_section_value = await gn_section_input.get_attribute("value")
            if not gn_section_value:
                print("gnSection å­—æ®µå€¼ä¸ºç©º")
                await browser.close()
                return concepts_list, stocks_list
            
            # è§£æ JSON æ•°æ®
            gn_data = json.loads(gn_section_value)
            
            # æå–æ¿å—åç§°å’Œä»£ç 
            thsgnbk = []
            bkcode = []  # platecode - ä¿å­˜åˆ°æ•°æ®åº“
            cid_list = []  # cid - ç”¨äºæ„å»ºURL
            
            for key, value in gn_data.items():
                if isinstance(value, dict) and "platecode" in value and "platename" in value and "cid" in value:
                    platecode = value["platecode"]
                    platename = value["platename"]
                    cid = value["cid"]
                    thsgnbk.append(platename)
                    bkcode.append(platecode)
                    cid_list.append(cid)
            
            data = {"Name": thsgnbk, "CID": cid_list}
            gnbk = pd.DataFrame(data, index=bkcode)

            total_concepts_count = len(gnbk)
            print(f"æ‰¾åˆ° {total_concepts_count} ä¸ªæ¿å—")

            processed_concepts = 0

            for index, row in gnbk.iterrows():
                bk_code = index  # platecode - ä¿å­˜åˆ°æ•°æ®åº“
                cid = row["CID"]  # cid - ç”¨äºæ„å»ºURL
                name = row["Name"]
                stocks_data = []  # å­˜å‚¨è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…æ‹¬ä»£ç ã€æµé€šå¸‚å€¼ã€å¸‚ç›ˆç‡

                url = p_url + "/detail/code/" + cid + "/"
                print(f"å¤„ç†æ¿å—: {name} (platecode={bk_code}, cid={cid})")
                report_rate_limit_status()

                # è®¿é—®è¯¦æƒ…é¡µ
                if not await safe_page_navigation(page, url, timeout=30000):
                    print(f"  é¡µé¢å¯¼èˆªå¤±è´¥ï¼Œè·³è¿‡æ­¤æ¿å—")
                    continue
                print("  ç­‰å¾…é¡µé¢åŠ è½½...")
                await page.wait_for_timeout(5000)

                try:
                    # ç­‰å¾…è¡¨æ ¼åŠ è½½
                    await page.wait_for_selector(
                        "table.m-table tbody tr", timeout=10000
                    )
                    print("  è¡¨æ ¼å·²åŠ è½½")

                except Exception as e:
                    print(f"  è¡¨æ ¼åŠ è½½å¤±è´¥: {e}ï¼Œè·³è¿‡æ­¤æ¿å—")
                    continue

                # ç›´æ¥ä»å½“å‰é¡µé¢æå–æˆåˆ†è‚¡
                count = 1
                max_pages = 999  # é‡‡é›†æ‰€æœ‰é¡µ

                while count <= max_pages:
                    try:
                        # æå–å½“å‰é¡µçš„è¡¨æ ¼æ•°æ®
                        stock_rows = await page.query_selector_all(
                            "table.m-table tbody tr"
                        )
                        page_data = []

                        for row in stock_rows:
                            cols = await row.query_selector_all("td")
                            if len(cols) >= 13:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                                # æå–è‚¡ç¥¨ä»£ç  (åˆ—1)
                                code_elem = await cols[1].query_selector("a")
                                if code_elem:
                                    code_text = await code_elem.text_content()
                                    stock_code = (
                                        code_text.strip() if code_text else None
                                    )

                                    if stock_code:
                                        # æå–æµé€šå¸‚å€¼ (åˆ—12)
                                        market_cap_text = await cols[12].text_content()
                                        market_cap = parse_market_cap(
                                            market_cap_text.strip()
                                        )

                                        # æå–å¸‚ç›ˆç‡ (åˆ—13)
                                        pe_text = await cols[13].text_content()
                                        pe_ratio = parse_pe_ratio(pe_text.strip())

                                        page_data.append(
                                            {
                                                "code": stock_code,
                                                "market_cap": market_cap,
                                                "pe_ratio": pe_ratio,
                                            }
                                        )

                        if page_data:
                            print(f"  ç¬¬ {count} é¡µ: æ‰¾åˆ° {len(page_data)} åªè‚¡ç¥¨")
                            stocks_data.extend(page_data)
                        else:
                            print(f"  ç¬¬ {count} é¡µ: æ— æ•°æ®")
                            break

                        # å¦‚æœæ˜¯ç¬¬ä¸€é¡µï¼Œå°è¯•è·å–æ€»é¡µæ•°
                        if count == 1:
                            try:
                                page_elem = await page.query_selector(
                                    "span#m-page, div.m-pager .page_info"
                                )
                                if page_elem:
                                    page_text = await page_elem.text_content()
                                    import re

                                    match = re.search(r"(\d+)/(\d+)", page_text)
                                    if match:
                                        total_pages = int(match.group(2))
                                        max_pages = total_pages
                                        print(f"  å…± {total_pages} é¡µ")
                            except Exception:
                                pass

                        # å¦‚æœè¿˜æœ‰ä¸‹ä¸€é¡µï¼Œç‚¹å‡»ä¸‹ä¸€é¡µ
                        if count < max_pages:
                            try:
                                # æŸ¥æ‰¾"ä¸‹ä¸€é¡µ"é“¾æ¥
                                next_link = None
                                page_links = await page.query_selector_all(
                                    "div.m-pager a.changePage"
                                )
                                for link in page_links:
                                    link_text = await link.text_content()
                                    if "ä¸‹ä¸€é¡µ" in link_text:
                                        next_link = link
                                        break

                                if next_link:
                                    print("  ç‚¹å‡»ä¸‹ä¸€é¡µ...")
                                    await next_link.click()
                                    await page.wait_for_timeout(3000)  # ç­‰å¾…é¡µé¢åŠ è½½

                                    # ç­‰å¾…æ–°è¡¨æ ¼åŠ è½½
                                    await page.wait_for_selector(
                                        "table.m-table tbody tr", timeout=5000
                                    )
                                    count += 1
                                else:
                                    print("  æ²¡æœ‰ä¸‹ä¸€é¡µï¼Œç»“æŸ")
                                    break
                            except Exception as e:
                                print(f"  ç¿»é¡µå¤±è´¥: {e}ï¼Œç»“æŸ")
                                break
                        else:
                            break

                    except Exception as e:
                        print(f"  ç¬¬ {count} é¡µå¤„ç†å¤±è´¥: {e}")
                        break

                # ä¿å­˜æ‰€æœ‰æ¿å—
                if len(stocks_data) > 0:
                    # è®¡ç®—æ¿å—æ€»å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰
                    total_market_cap = sum(
                        stock["market_cap"] for stock in stocks_data 
                        if stock["market_cap"] is not None
                    )
                    
                    concept_entry = {
                        "code": bk_code,
                        "name": name,
                        "stock_count": len(stocks_data),
                        "total_market_cap": total_market_cap,
                    }
                    concept_stock_entries = [
                        {
                            "concept_code": bk_code,
                            "stock_code": stock["code"],
                            "circulating_market_cap": stock["market_cap"],
                            "pe_ratio": stock["pe_ratio"],
                        }
                        for stock in stocks_data
                    ]

                    concepts_list.append(concept_entry)
                    stocks_list.extend(concept_stock_entries)

                    processed_concepts += 1

                    if on_concept_collected:
                        try:
                            on_concept_collected(
                                concept_entry,
                                concept_stock_entries,
                                processed_concepts,
                                total_concepts_count,
                            )
                        except Exception as callback_error:
                            print(
                                f"å®æ—¶ä¿å­˜æ¿å— {name} å¤±è´¥: {callback_error}"
                            )

                    print(f"æ¿å— {name} å®Œæˆï¼Œå…± {len(stocks_data)} åªæˆåˆ†è‚¡")
                else:
                    print(f"æ¿å— {name} æ— æˆåˆ†è‚¡ï¼Œè·³è¿‡")

            await browser.close()
            print(f"é‡‡é›†å®Œæˆ: {len(concepts_list)} ä¸ªæ¿å—, {len(stocks_list)} åªæˆåˆ†è‚¡")

        except Exception as e:
            print(f"çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            print("é”™è¯¯è¯¦æƒ…:")
            traceback.print_exc()
            print(f"å·²é‡‡é›†: {len(concepts_list)} ä¸ªæ¿å—, {len(stocks_list)} åªæˆåˆ†è‚¡")
            await browser.close()
            # Return collected data even if an error occurred
            return concepts_list, stocks_list

    return concepts_list, stocks_list


if __name__ == "__main__":
    asyncio.run(crawl("http://q.10jqka.com.cn/thshy"))
    asyncio.run(crawl("http://q.10jqka.com.cn/gn"))
    asyncio.run(crawl("http://q.10jqka.com.cn/dy"))
    exit()
