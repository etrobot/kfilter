#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯è‚¡ç¥¨æ•°æ®å¤„ç†å®Œæ•´æµç¨‹
åŒ…æ‹¬ï¼šæ•°æ®åº“åˆ›å»ºã€æ•°æ®è·å–ã€å­˜å‚¨ã€Kçº¿è®¡ç®—ã€å› å­åˆ†æ
"""

import logging
import sys
from datetime import date
import pandas as pd
import akshare as ak

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_database_setup():
    """æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–"""
    logger.info("=== æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ– ===")
    from models import create_db_and_tables
    create_db_and_tables()
    logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
    return True


def test_fetch_spot_data():
    """æµ‹è¯•è·å–å®æ—¶è¡Œæƒ…æ•°æ®"""
    logger.info("=== æµ‹è¯•è·å–å®æ—¶è¡Œæƒ…æ•°æ® ===")
    from data_processor import fetch_spot
    spot_data = fetch_spot()
    
    if spot_data.empty:
        logger.warning("âš ï¸ å®æ—¶è¡Œæƒ…æ•°æ®ä¸ºç©º")
        return False, None
        
    logger.info(f"âœ… è·å–å®æ—¶è¡Œæƒ…æˆåŠŸï¼Œå…± {len(spot_data)} æ¡è®°å½•")
    logger.info(f"æ•°æ®åˆ—: {list(spot_data.columns)}")
    return True, spot_data


def test_save_basic_info(spot_data):
    """æµ‹è¯•ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    logger.info("=== æµ‹è¯•ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ ===")
    from stock_data_manager import save_stock_basic_info
    saved_count = save_stock_basic_info(spot_data.head(10))  # åªæµ‹è¯•å‰10æ¡
    logger.info(f"âœ… ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æˆåŠŸï¼Œå…± {saved_count} æ¡")
    return True


def test_save_spot_as_daily(spot_data):
    """æµ‹è¯•ä¿å­˜å®æ—¶æ•°æ®ä¸ºä»Šæ—¥è¡Œæƒ…"""
    logger.info("=== æµ‹è¯•ä¿å­˜å®æ—¶æ•°æ®ä¸ºä»Šæ—¥è¡Œæƒ… ===")
    from stock_data_manager import save_spot_as_daily_data
    saved_count = save_spot_as_daily_data(spot_data.head(10))  # åªæµ‹è¯•å‰10æ¡
    logger.info(f"âœ… ä¿å­˜ä»Šæ—¥è¡Œæƒ…æˆåŠŸï¼Œå…± {saved_count} æ¡")
    return True


def test_fetch_and_save_history():
    """æµ‹è¯•è·å–å¹¶ä¿å­˜å†å²æ•°æ®"""
    logger.info("=== æµ‹è¯•è·å–å¹¶ä¿å­˜å†å²æ•°æ® ===")
    from data_processor import fetch_history
    from stock_data_manager import save_daily_data, get_missing_daily_data
    
    # é€‰æ‹©å‡ ä¸ªæµ‹è¯•è‚¡ç¥¨ä»£ç 
    test_codes = ["000001", "000002", "600000"]
    logger.info(f"æµ‹è¯•è‚¡ç¥¨ä»£ç : {test_codes}")
    
    # æ£€æŸ¥ç¼ºå¤±æ•°æ®
    missing_data = get_missing_daily_data(test_codes)
    logger.info(f"éœ€è¦è¡¥å……æ•°æ®çš„è‚¡ç¥¨: {len(missing_data)} ä¸ª")
    
    if missing_data:
        # è·å–å†å²æ•°æ®ï¼ˆåªè·å–æœ€è¿‘5å¤©æµ‹è¯•ï¼‰
        history_data = fetch_history(list(missing_data.keys())[:2], days=5)  # åªæµ‹è¯•å‰2ä¸ª
        
        if history_data:
            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = save_daily_data(history_data)
            logger.info(f"âœ… è·å–å¹¶ä¿å­˜å†å²æ•°æ®æˆåŠŸï¼Œå…± {saved_count} æ¡")
            return True, history_data
        else:
            logger.warning("âš ï¸ å†å²æ•°æ®è·å–ä¸ºç©º")
            return False, None
    else:
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•è‚¡ç¥¨æ•°æ®éƒ½æ˜¯æœ€æ–°çš„")
        return True, {}


def test_weekly_monthly_calculation():
    """æµ‹è¯•å‘¨KæœˆKè®¡ç®—"""
    logger.info("=== æµ‹è¯•å‘¨KæœˆKè®¡ç®— ===")
    from market_data_processor import calculate_and_save_weekly_data, calculate_and_save_monthly_data
    
    test_codes = ["000001", "000002"]
    
    # è®¡ç®—å‘¨K
    weekly_count = calculate_and_save_weekly_data(test_codes)
    logger.info(f"âœ… è®¡ç®—å‘¨Kçº¿æˆåŠŸï¼Œå…± {weekly_count} æ¡")
    
    # è®¡ç®—æœˆK
    monthly_count = calculate_and_save_monthly_data(test_codes)
    logger.info(f"âœ… è®¡ç®—æœˆKçº¿æˆåŠŸï¼Œå…± {monthly_count} æ¡")
    
    return True


def test_data_loading():
    """æµ‹è¯•ä»æ•°æ®åº“åŠ è½½æ•°æ®"""
    logger.info("=== æµ‹è¯•ä»æ•°æ®åº“åŠ è½½æ•°æ® ===")
    from stock_data_manager import load_daily_data_for_analysis
    from market_data_processor import get_weekly_data, get_monthly_data
    
    test_codes = ["000001", "000002"]
    
    # åŠ è½½æ—¥Kæ•°æ®
    daily_data = load_daily_data_for_analysis(test_codes, limit=10)
    logger.info(f"âœ… åŠ è½½æ—¥Kæ•°æ®æˆåŠŸï¼Œå…± {len(daily_data)} ä¸ªè‚¡ç¥¨")
    
    # åŠ è½½å‘¨Kæ•°æ®
    weekly_data = get_weekly_data(test_codes, limit=5)
    logger.info(f"âœ… åŠ è½½å‘¨Kæ•°æ®æˆåŠŸï¼Œå…± {len(weekly_data)} æ¡è®°å½•")
    
    # åŠ è½½æœˆKæ•°æ®
    monthly_data = get_monthly_data(test_codes, limit=3)
    logger.info(f"âœ… åŠ è½½æœˆKæ•°æ®æˆåŠŸï¼Œå…± {len(monthly_data)} æ¡è®°å½•")
    
    return True, daily_data


def test_factor_calculation(spot_data, daily_data):
    """æµ‹è¯•å› å­è®¡ç®—"""
    logger.info("=== æµ‹è¯•å› å­è®¡ç®— ===")
    from data_processor import compute_factors
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    top_spot = spot_data.head(5).copy()  # åªæµ‹è¯•å‰5ä¸ªè‚¡ç¥¨
    
    # è®¡ç®—å› å­
    factors_df = compute_factors(top_spot, daily_data)
    
    if not factors_df.empty:
        logger.info(f"âœ… å› å­è®¡ç®—æˆåŠŸï¼Œå…± {len(factors_df)} æ¡ç»“æœ")
        logger.info(f"å› å­åˆ—: {list(factors_df.columns)}")
        
        # æ˜¾ç¤ºå‰å‡ æ¡ç»“æœ
        if len(factors_df) > 0:
            logger.info("å‰3æ¡å› å­ç»“æœ:")
            for _, row in factors_df.head(3).iterrows():
                logger.info(f"  {row.get('ä»£ç ', 'N/A')} {row.get('åç§°', 'N/A')}: "
                          f"åŠ¨é‡={row.get('åŠ¨é‡å› å­', 'N/A'):.4f}, "
                          f"æ”¯æ’‘={row.get('æ”¯æ’‘å› å­', 'N/A'):.4f}")
        return True
    else:
        logger.warning("âš ï¸ å› å­è®¡ç®—ç»“æœä¸ºç©º")
        return False


def test_technical_indicators():
    """æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
    logger.info("=== æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®— ===")
    from market_data_processor import calculate_technical_indicators
    from stock_data_manager import load_daily_data_for_analysis
    
    test_codes = ["000001", "000002"]
    daily_data = load_daily_data_for_analysis(test_codes, limit=100)  # åŠ è½½æ›´å¤šæ•°æ®ç”¨äºè®¡ç®—æŒ‡æ ‡
    
    if not daily_data:
        logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ—¥çº¿æ•°æ®")
        return False
        
    # å¯¹æ¯åªè‚¡ç¥¨çš„æ•°æ®åˆ†åˆ«è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    success_count = 0
    for code, df in daily_data.items():
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        indicators_df = calculate_technical_indicators(df)
        
        if not indicators_df.empty:
            logger.info(f"âœ… {code} æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æˆåŠŸï¼Œå…± {len(indicators_df)} æ¡è®°å½•")
            logger.info(f"{code} å¯ç”¨æŒ‡æ ‡: {[col for col in indicators_df.columns if col not in df.columns]}")
            success_count += 1
    
    if success_count > 0:
        logger.info(f"âœ… å…± {success_count} åªè‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æˆåŠŸ")
        return True
    else:
        logger.warning("âš ï¸ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ç»“æœä¸ºç©º")
        return False


def check_database_content():
    """æ£€æŸ¥æ•°æ®åº“å†…å®¹"""
    logger.info("=== æ£€æŸ¥æ•°æ®åº“å†…å®¹ ===")
    from sqlalchemy import create_engine, inspect
    from models import SQLALCHEMY_DATABASE_URL
    
    engine = create_engine(SQLALCHEMY_DATABASE_URL)
    inspector = inspect(engine)
    
    # è·å–æ‰€æœ‰è¡¨
    tables = inspector.get_table_names()
    logger.info(f"æ•°æ®åº“è¡¨: {tables}")
    
    # æ˜¾ç¤ºæ¯ä¸ªè¡¨çš„å‰5æ¡è®°å½•
    for table in tables:
        with engine.connect() as conn:
            result = conn.execute(f"SELECT * FROM {table} LIMIT 5").fetchall()
            logger.info(f"\nè¡¨ {table} çš„å‰ {len(result)} æ¡è®°å½•:")
            for row in result:
                logger.info(f"  {row}")
    
    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("\n" + "="*50)
    logger.info("ğŸ“Š å¼€å§‹æµ‹è¯•è‚¡ç¥¨æ•°æ®å¤„ç†æµç¨‹")
    logger.info("="*50 + "\n")
    
    success = True
    
    # 1. åˆå§‹åŒ–æ•°æ®åº“
    if not test_database_setup():
        success = False
        logger.error("âŒ æ•°æ®åº“åˆå§‹åŒ–æµ‹è¯•å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
        return False
    
    # 2. è·å–å®æ—¶è¡Œæƒ…
    spot_success, spot_data = test_fetch_spot_data()
    if not spot_success or spot_data is None:
        success = False
        logger.error("âŒ è·å–å®æ—¶è¡Œæƒ…æµ‹è¯•å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
        return False
    
    # 3. ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    if not test_save_basic_info(spot_data):
        success = False
        logger.warning("âš ï¸ ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æµ‹è¯•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    # 4. ä¿å­˜å®æ—¶æ•°æ®ä¸ºä»Šæ—¥è¡Œæƒ…
    if not test_save_spot_as_daily(spot_data):
        success = False
        logger.warning("âš ï¸ ä¿å­˜ä»Šæ—¥è¡Œæƒ…æµ‹è¯•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    # 5. è·å–å¹¶ä¿å­˜å†å²æ•°æ®
    history_success, history_data = test_fetch_and_save_history()
    if not history_success:
        success = False
        logger.warning("âš ï¸ è·å–å¹¶ä¿å­˜å†å²æ•°æ®æµ‹è¯•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    # 6. è®¡ç®—å‘¨KæœˆK
    if not test_weekly_monthly_calculation():
        success = False
        logger.warning("âš ï¸ å‘¨KæœˆKè®¡ç®—æµ‹è¯•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    # 7. æµ‹è¯•æ•°æ®åŠ è½½
    data_loading_success, daily_data = test_data_loading()
    if not data_loading_success or daily_data is None:
        success = False
        logger.warning("âš ï¸ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    # 8. æµ‹è¯•å› å­è®¡ç®—
    if not test_factor_calculation(spot_data, daily_data if 'daily_data' in locals() else {}):
        success = False
        logger.warning("âš ï¸ å› å­è®¡ç®—æµ‹è¯•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    # 9. æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
    if not test_technical_indicators():
        success = False
        logger.warning("âš ï¸ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æµ‹è¯•å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    # 10. æ£€æŸ¥æ•°æ®åº“å†…å®¹
    if not check_database_content():
        success = False
        logger.warning("âš ï¸ æ•°æ®åº“å†…å®¹æ£€æŸ¥å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
    
    if success:
        logger.info("\nâœ… æ‰€æœ‰æµ‹è¯•æ‰§è¡Œå®Œæˆï¼Œæ²¡æœ‰å‘ç°é”™è¯¯ï¼")
    else:
        logger.warning("\nâš ï¸ æµ‹è¯•å®Œæˆï¼Œä½†éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æŸ¥çœ‹ä¸Šé¢çš„æ—¥å¿—äº†è§£è¯¦æƒ…ã€‚")
    
    return success



if __name__ == "__main__":
    df=ak.stock_zh_a_hist(symbol="000001", period="daily", start_date="20250101", end_date="20250906")
    print(df)
