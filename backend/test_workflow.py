#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯è‚¡ç¥¨æ•°æ®å¤„ç†å®Œæ•´æµç¨‹
åŒ…æ‹¬ï¼šæ•°æ®åº“åˆ›å»ºã€æ•°æ®è·å–ã€å­˜å‚¨ã€Kçº¿è®¡ç®—ã€å› å­åˆ†æ
"""

import logging
import sys
from datetime import date
import pandas as pd

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_database_setup():
    """æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–"""
    logger.info("=== æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ– ===")
    try:
        from models import create_db_and_tables
        create_db_and_tables()
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def test_fetch_spot_data():
    """æµ‹è¯•è·å–å®æ—¶è¡Œæƒ…æ•°æ®"""
    logger.info("=== æµ‹è¯•è·å–å®æ—¶è¡Œæƒ…æ•°æ® ===")
    try:
        from data_processor import fetch_spot
        spot_data = fetch_spot()
        
        if spot_data.empty:
            logger.warning("âš ï¸ å®æ—¶è¡Œæƒ…æ•°æ®ä¸ºç©º")
            return False, None
            
        logger.info(f"âœ… è·å–å®æ—¶è¡Œæƒ…æˆåŠŸï¼Œå…± {len(spot_data)} æ¡è®°å½•")
        logger.info(f"æ•°æ®åˆ—: {list(spot_data.columns)}")
        return True, spot_data
    except Exception as e:
        logger.error(f"âŒ è·å–å®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
        return False, None


def test_save_basic_info(spot_data):
    """æµ‹è¯•ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    logger.info("=== æµ‹è¯•ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ ===")
    try:
        from stock_data_manager import save_stock_basic_info
        saved_count = save_stock_basic_info(spot_data.head(10))  # åªæµ‹è¯•å‰10æ¡
        logger.info(f"âœ… ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æˆåŠŸï¼Œå…± {saved_count} æ¡")
        return True
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
        return False


def test_save_spot_as_daily(spot_data):
    """æµ‹è¯•ä¿å­˜å®æ—¶æ•°æ®ä¸ºä»Šæ—¥è¡Œæƒ…"""
    logger.info("=== æµ‹è¯•ä¿å­˜å®æ—¶æ•°æ®ä¸ºä»Šæ—¥è¡Œæƒ… ===")
    try:
        from stock_data_manager import save_spot_as_daily_data
        saved_count = save_spot_as_daily_data(spot_data.head(10))  # åªæµ‹è¯•å‰10æ¡
        logger.info(f"âœ… ä¿å­˜ä»Šæ—¥è¡Œæƒ…æˆåŠŸï¼Œå…± {saved_count} æ¡")
        return True
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜ä»Šæ—¥è¡Œæƒ…å¤±è´¥: {e}")
        return False


def test_fetch_and_save_history():
    """æµ‹è¯•è·å–å¹¶ä¿å­˜å†å²æ•°æ®"""
    logger.info("=== æµ‹è¯•è·å–å¹¶ä¿å­˜å†å²æ•°æ® ===")
    try:
        from data_processor import fetch_history
        from stock_data_manager import save_daily_data, get_missing_daily_data
        
        # é€‰æ‹©å‡ ä¸ªæµ‹è¯•è‚¡ç¥¨ä»£ç 
        test_codes = ["000001", "000002", "600000"]
        logger.info(f"æµ‹è¯•è‚¡ç¥¨ä»£ç : {test_codes}")
        
        # æ£€æŸ¥ç¼ºå¤±æ•°æ®
        missing_data = get_missing_daily_data(test_codes)
        logger.info(f"éœ€è¦è¡¥å……æ•°æ®çš„è‚¡ç¥¨: {len(missing_data)} ä¸ª")
        
        if missing_data:
            # è·å–å†å²æ•°æ®ï¼ˆåªè·å–æœ€è¿‘5å¤©æµ‹è¯•ï¼‰
            history_data = fetch_history(list(missing_data.keys())[:2], days=5)  # åªæµ‹è¯•å‰2ä¸ª
            
            if history_data:
                # ä¿å­˜åˆ°æ•°æ®åº“
                saved_count = save_daily_data(history_data)
                logger.info(f"âœ… è·å–å¹¶ä¿å­˜å†å²æ•°æ®æˆåŠŸï¼Œå…± {saved_count} æ¡")
                return True, history_data
            else:
                logger.warning("âš ï¸ å†å²æ•°æ®è·å–ä¸ºç©º")
                return False, None
        else:
            logger.info("âœ… æ‰€æœ‰æµ‹è¯•è‚¡ç¥¨æ•°æ®éƒ½æ˜¯æœ€æ–°çš„")
            return True, {}
            
    except Exception as e:
        logger.error(f"âŒ è·å–å¹¶ä¿å­˜å†å²æ•°æ®å¤±è´¥: {e}")
        return False, None


def test_weekly_monthly_calculation():
    """æµ‹è¯•å‘¨KæœˆKè®¡ç®—"""
    logger.info("=== æµ‹è¯•å‘¨KæœˆKè®¡ç®— ===")
    try:
        from market_data_processor import calculate_and_save_weekly_data, calculate_and_save_monthly_data
        
        test_codes = ["000001", "000002"]
        
        # è®¡ç®—å‘¨K
        weekly_count = calculate_and_save_weekly_data(test_codes)
        logger.info(f"âœ… è®¡ç®—å‘¨Kçº¿æˆåŠŸï¼Œå…± {weekly_count} æ¡")
        
        # è®¡ç®—æœˆK
        monthly_count = calculate_and_save_monthly_data(test_codes)
        logger.info(f"âœ… è®¡ç®—æœˆKçº¿æˆåŠŸï¼Œå…± {monthly_count} æ¡")
        
        return True
    except Exception as e:
        logger.error(f"âŒ å‘¨KæœˆKè®¡ç®—å¤±è´¥: {e}")
        return False


def test_data_loading():
    """æµ‹è¯•ä»æ•°æ®åº“åŠ è½½æ•°æ®"""
    logger.info("=== æµ‹è¯•ä»æ•°æ®åº“åŠ è½½æ•°æ® ===")
    try:
        from stock_data_manager import load_daily_data_for_analysis
        from market_data_processor import get_weekly_data, get_monthly_data
        
        test_codes = ["000001", "000002"]
        
        # åŠ è½½æ—¥Kæ•°æ®
        daily_data = load_daily_data_for_analysis(test_codes, limit=10)
        logger.info(f"âœ… åŠ è½½æ—¥Kæ•°æ®æˆåŠŸï¼Œå…± {len(daily_data)} ä¸ªè‚¡ç¥¨")
        
        # åŠ è½½å‘¨Kæ•°æ®
        weekly_data = get_weekly_data(test_codes, limit=5)
        logger.info(f"âœ… åŠ è½½å‘¨Kæ•°æ®æˆåŠŸï¼Œå…± {len(weekly_data)} æ¡è®°å½•")
        
        # åŠ è½½æœˆKæ•°æ®
        monthly_data = get_monthly_data(test_codes, limit=3)
        logger.info(f"âœ… åŠ è½½æœˆKæ•°æ®æˆåŠŸï¼Œå…± {len(monthly_data)} æ¡è®°å½•")
        
        return True, daily_data
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False, None


def test_factor_calculation(spot_data, daily_data):
    """æµ‹è¯•å› å­è®¡ç®—"""
    logger.info("=== æµ‹è¯•å› å­è®¡ç®— ===")
    try:
        from data_processor import compute_factors
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        top_spot = spot_data.head(5).copy()  # åªæµ‹è¯•å‰5ä¸ªè‚¡ç¥¨
        
        # è®¡ç®—å› å­
        factors_df = compute_factors(top_spot, daily_data)
        
        if not factors_df.empty:
            logger.info(f"âœ… å› å­è®¡ç®—æˆåŠŸï¼Œå…± {len(factors_df)} æ¡ç»“æœ")
            logger.info(f"å› å­åˆ—: {list(factors_df.columns)}")
            
            # æ˜¾ç¤ºå‰å‡ æ¡ç»“æœ
            if len(factors_df) > 0:
                logger.info("å‰3æ¡å› å­ç»“æœ:")
                for _, row in factors_df.head(3).iterrows():
                    logger.info(f"  {row.get('ä»£ç ', 'N/A')} {row.get('åç§°', 'N/A')}: "
                              f"åŠ¨é‡={row.get('åŠ¨é‡å› å­', 'N/A'):.4f}, "
                              f"æ”¯æ’‘={row.get('æ”¯æ’‘å› å­', 'N/A'):.4f}")
            return True
        else:
            logger.warning("âš ï¸ å› å­è®¡ç®—ç»“æœä¸ºç©º")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å› å­è®¡ç®—å¤±è´¥: {e}")
        return False


def test_technical_indicators():
    """æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®—"""
    logger.info("=== æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®— ===")
    try:
        from market_data_processor import calculate_technical_indicators
        from stock_data_manager import load_daily_data_for_analysis
        
        # åŠ è½½ä¸€ä¸ªè‚¡ç¥¨çš„æ•°æ®
        daily_data = load_daily_data_for_analysis(["000001"], limit=30)
        
        if daily_data and "000001" in daily_data:
            df = daily_data["000001"]
            indicators_df = calculate_technical_indicators(df)
            
            logger.info(f"âœ… æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æˆåŠŸï¼Œæ•°æ®è¡Œæ•°: {len(indicators_df)}")
            logger.info(f"åŒ…å«æŒ‡æ ‡: {[col for col in indicators_df.columns if col.startswith(('MA', 'RSI', 'BB_'))]}")
            return True
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ•°æ®")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return False


def check_database_content():
    """æ£€æŸ¥æ•°æ®åº“å†…å®¹"""
    logger.info("=== æ£€æŸ¥æ•°æ®åº“å†…å®¹ ===")
    try:
        from sqlmodel import Session, select, func
        from models import engine, StockBasicInfo, DailyMarketData, WeeklyMarketData, MonthlyMarketData
        
        with Session(engine) as session:
            # ç»Ÿè®¡å„è¡¨è®°å½•æ•°
            basic_count = session.exec(select(func.count(StockBasicInfo.code))).one()
            daily_count = session.exec(select(func.count(DailyMarketData.id))).one()
            weekly_count = session.exec(select(func.count(WeeklyMarketData.id))).one()
            monthly_count = session.exec(select(func.count(MonthlyMarketData.id))).one()
            
            logger.info(f"âœ… æ•°æ®åº“ç»Ÿè®¡:")
            logger.info(f"  è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯: {basic_count} æ¡")
            logger.info(f"  æ—¥Kçº¿æ•°æ®: {daily_count} æ¡")
            logger.info(f"  å‘¨Kçº¿æ•°æ®: {weekly_count} æ¡")
            logger.info(f"  æœˆKçº¿æ•°æ®: {monthly_count} æ¡")
            
            # æ˜¾ç¤ºæœ€æ–°çš„å‡ æ¡è®°å½•
            latest_daily = session.exec(
                select(DailyMarketData).order_by(DailyMarketData.date.desc()).limit(3)
            ).all()
            
            if latest_daily:
                logger.info("æœ€æ–°æ—¥Kçº¿è®°å½•:")
                for record in latest_daily:
                    logger.info(f"  {record.code} {record.date}: æ”¶ç›˜={record.close_price}")
        
        return True
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“æ£€æŸ¥å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹è‚¡ç¥¨æ•°æ®å¤„ç†å®Œæ•´æµç¨‹æµ‹è¯•")
    
    results = []
    
    # 1. æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–
    results.append(("æ•°æ®åº“åˆå§‹åŒ–", test_database_setup()))
    
    # 2. æµ‹è¯•è·å–å®æ—¶æ•°æ®
    success, spot_data = test_fetch_spot_data()
    results.append(("è·å–å®æ—¶è¡Œæƒ…", success))
    
    if not success or spot_data is None:
        logger.error("âŒ æ— æ³•è·å–å®æ—¶æ•°æ®ï¼Œåç»­æµ‹è¯•æ— æ³•è¿›è¡Œ")
        return False
    
    # 3. æµ‹è¯•ä¿å­˜åŸºæœ¬ä¿¡æ¯
    results.append(("ä¿å­˜è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯", test_save_basic_info(spot_data)))
    
    # 4. æµ‹è¯•ä¿å­˜ä»Šæ—¥è¡Œæƒ…
    results.append(("ä¿å­˜ä»Šæ—¥è¡Œæƒ…", test_save_spot_as_daily(spot_data)))
    
    # 5. æµ‹è¯•å†å²æ•°æ®å¤„ç†
    success, history_data = test_fetch_and_save_history()
    results.append(("è·å–å¹¶ä¿å­˜å†å²æ•°æ®", success))
    
    # 6. æµ‹è¯•å‘¨KæœˆKè®¡ç®—
    results.append(("å‘¨KæœˆKè®¡ç®—", test_weekly_monthly_calculation()))
    
    # 7. æµ‹è¯•æ•°æ®åŠ è½½
    success, daily_data = test_data_loading()
    results.append(("æ•°æ®åŠ è½½", success))
    
    # 8. æµ‹è¯•å› å­è®¡ç®—
    if success and daily_data:
        results.append(("å› å­è®¡ç®—", test_factor_calculation(spot_data, daily_data)))
    
    # 9. æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡
    results.append(("æŠ€æœ¯æŒ‡æ ‡è®¡ç®—", test_technical_indicators()))
    
    # 10. æ£€æŸ¥æ•°æ®åº“å†…å®¹
    results.append(("æ•°æ®åº“å†…å®¹æ£€æŸ¥", check_database_content()))
    
    # æ±‡æ€»ç»“æœ
    logger.info("\n" + "="*50)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    logger.info("="*50)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name:<20} {status}")
        if result:
            passed += 1
    
    logger.info("="*50)
    logger.info(f"æµ‹è¯•é€šè¿‡: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è‚¡ç¥¨æ•°æ®å¤„ç†æµç¨‹æ­£å¸¸å·¥ä½œ")
        return True
    else:
        logger.warning(f"âš ï¸ æœ‰ {total-passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
        return False


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
        sys.exit(1)